{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T14:14:10.744078Z",
     "start_time": "2020-10-18T14:14:10.607070Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pickle\n",
    "import sys\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T14:14:11.226188Z",
     "start_time": "2020-10-18T14:14:11.079076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('raph-base')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "pd.set_option('precision', 2)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T14:14:11.580189Z",
     "start_time": "2020-10-18T14:14:11.454192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r2d4\\miniconda3\\envs\\py3\\python.exe\n",
      "3.8.3 (default, May 19 2020, 06:50:17) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Check Text Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T14:14:12.861355Z",
     "start_time": "2020-10-18T14:14:12.717900Z"
    }
   },
   "outputs": [],
   "source": [
    "# load text data\n",
    "\n",
    "def load_text_data(path: Path, encoding: str=\"UTF-8\") -> str:\n",
    "    \"\"\"Load textcorpus from file into a string.\n",
    "    Replace double line breaks with simple break.\n",
    "    \"\"\"\n",
    "    text_path = Path(path)\n",
    "    with text_path.open(mode='r'):\n",
    "        corpus = text_path.read_text(encoding=encoding)\n",
    "        corpus = corpus.replace(\"\\n\\n\", \"\\n\")\n",
    "        return corpus\n",
    "\n",
    "corpus = load_text_data(\"../data/training/text/text_corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T14:14:13.405641Z",
     "start_time": "2020-10-18T14:14:13.141166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 282,312\n",
      "Approx. number of unique words: 21,947\n",
      "Number of lines: 1,836\n",
      "Average number of words in each line: 154\n"
     ]
    }
   ],
   "source": [
    "# Print some stats\n",
    "print(f\"Total number of words: {len(corpus.split()):,.0f}\")\n",
    "print(f\"Approx. number of unique words: {len({word: None for word in corpus.split()}):,.0f}\")\n",
    "\n",
    "lines = corpus.split('\\n')\n",
    "print(f\"Number of lines: {len(lines):,.0f}\")\n",
    "word_count_line = [len(line.split()) for line in lines]\n",
    "print(f\"Average number of words in each line: {round(np.average(word_count_line),0):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T14:37:52.605739Z",
     "start_time": "2020-10-18T14:37:52.477960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The lines 4 to 5:\n",
      "\n",
      "Implement Consulting Group, Director (2015-) GN ReSound, Global Finance Transformation Director (2015) Implement Consulting Group, Senior Manager (2012-2015) Accenture Management Consulting, Senior Manager (2009-2012) Coca-Cola HBC, Corporate Finance Business Systems Lead, Strategic Services (2004-2009) Andersen Consulting/Accenture, Manager (1996-2004)\n",
      "\n",
      "Programme for Management Excellence, IMD Switzerland (2009) MSc in Business Administration (Strategy, Organisation and Leadership), Copenhagen Business School (1995) BSc in Economics and Business Administration, Copenhagen Business School (1993)\n"
     ]
    }
   ],
   "source": [
    "# Print some sample lines\n",
    "\n",
    "VIEW_LINE_RANGE = (4, 5)\n",
    "\n",
    "print(\"\\nThe lines {} to {}:\\n\".format(*VIEW_LINE_RANGE))\n",
    "print(\"\\n\\n\".join(corpus.split(\"\\n\")[VIEW_LINE_RANGE[0]:VIEW_LINE_RANGE[1]+1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build pre-processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T14:14:14.716764Z",
     "start_time": "2020-10-18T14:14:14.582653Z"
    }
   },
   "outputs": [],
   "source": [
    "TOKEN_LOOKUP = {\".\": \"<PERIOD>\",\n",
    "                \",\": \"<COMMA>\",\n",
    "                '\"': \"<QUOTDOUBLE>\",\n",
    "                \"'\": \"<QUOTSINGLE>\",\n",
    "                \":\": \"<COLON>\",\n",
    "                \";\": \"<SEMICOLON>\" ,\n",
    "                \"!\": \"<EXCLAMATIONMARK>\",\n",
    "                \"?\": \"<QUESTIONMARK>\",\n",
    "                \"(\": \"<LEFTPAREN>\",\n",
    "                \")\": \"<RIGHTPAREN>\",\n",
    "                \"-\": \"<DASH>\",\n",
    "                \"?\": \"<QUESTIONMARK>\",\n",
    "                \"\\n\": \"<NEWLINE>\",\n",
    "                \"_\": \"<UNDERSCORE>\",\n",
    "                \"PADDING\": '<PAD>'\n",
    "                }\n",
    "\n",
    "VIEW_LINE_RANGE = (0, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T14:26:11.880221Z",
     "start_time": "2020-10-18T14:26:11.736978Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_text_data(path: str, encoding: str=\"UTF-8\") -> str:\n",
    "    \"\"\"Load textcorpus from file into a string.\n",
    "    Replace double line breaks with simple break.\n",
    "    \"\"\"\n",
    "    text_path = Path(path)\n",
    "    with text_path.open(mode='r'):\n",
    "        text = text_path.read_text(encoding=encoding)\n",
    "        text = text.replace(\"\\n\\n\", \"\\n\")\n",
    "        return text\n",
    "\n",
    "    \n",
    "def print_some_text_stats(text: str):\n",
    "    \"\"\"Output some metrics for information.\"\"\"\n",
    "    print(f\"Approx. total number of words: {len(corpus.split()):,.0f}\")\n",
    "    print(f\"Approx. number of unique words: {len({word: None for word in corpus.split()}):,.0f}\")\n",
    "    lines = corpus.split('\\n')\n",
    "    print(f\"Number of lines: {len(lines):,.0f}\")\n",
    "    word_count_line = [len(line.split()) for line in lines]\n",
    "    print(f\"Average number of words in each line: {round(np.average(word_count_line),0):,.0f}\\n\\n\")\n",
    "\n",
    "\n",
    "def print_some_sample_lines(text: str, view_line_range: Tuple[int, int]=None):\n",
    "    \"\"\"Output some lines for information. This step is skipped by default.\n",
    "    To activate it a tuple with a view range is explicitely passed.\n",
    "    \"\"\"\n",
    "    if view_line_range:\n",
    "        print(\"\\nThe lines {} to {}:\\n\".format(*VIEW_LINE_RANGE))\n",
    "        print(\"\\n\\n\".join(text.split(\"\\n\")[VIEW_LINE_RANGE[0]:VIEW_LINE_RANGE[1]+1]))\n",
    "\n",
    "\n",
    "def clean_text(text: str, lookup: Dict[str, str]=TOKEN_LOOKUP) -> List[str]:\n",
    "    \"\"\"Normalize the text and convert the special characters with help of \n",
    "    a lookup dictionary, thereby ensuring that they are separated from the\n",
    "    actual words. So we can properly split the text and return a list of\n",
    "    all the words.\"\"\"\n",
    "    for special_char, token in TOKEN_LOOKUP.items():\n",
    "        text = text.replace(special_char, f\" {token} \")\n",
    "        text = text.lower()\n",
    "        # Add a special word that we will use later on\n",
    "        text = \"\".join([text, \" <PAD>\"])\n",
    "        return text.split()\n",
    "\n",
    "\n",
    "def create_encoding_dicts(text_list: List[str]) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
    "    \"\"\"Create two encoding dicts for the vocabulary int the text \n",
    "    (str2int, int2str). The vocabulary is sorted in descending by \n",
    "    frequency.\n",
    "    \"\"\"\n",
    "    # Get a list of unique words sorted by frequency using Counter()\n",
    "    word_counts = Counter(text_list)\n",
    "    word_list_sorted = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    \n",
    "    vocab_to_int = {word: pos for pos, word in enumerate(word_list_sorted)}\n",
    "    int_to_vocab = {pos: word for pos, word in enumerate(word_list_sorted)}\n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "\n",
    "def encode_text_to_int(text_list: List[str], vocab_to_int: Dict[str, int]) -> List[int]:\n",
    "    \"\"\"Translate the cleaned text (list) into a list of integers using\n",
    "    the encoding dict. This will be the text corpus for training the NN.\n",
    "    \"\"\"\n",
    "    return [vocab_to_int[word] for word in text_list]\n",
    "\n",
    "def pickle_preprocessed_text_data(path: str, data_objects: Iterable[Any]):\n",
    "    \"\"\"Save the necessary objects for the later steps in one single\n",
    "    binary pickle file.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    with open(path, \"wb\") as p_file: \n",
    "#         for obj in data_objects:\n",
    "        pickle.dump(data_objects, p_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T14:26:12.877195Z",
     "start_time": "2020-10-18T14:26:12.390200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx. total number of words: 282,312\n",
      "Approx. number of unique words: 21,947\n",
      "Number of lines: 1,836\n",
      "Average number of words in each line: 154\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = load_text_data(\"../data/training/text/text_corpus.txt\")\n",
    "print_some_text_stats(text)\n",
    "print_some_sample_lines(text)\n",
    "text_list =clean_text(text)\n",
    "vocab_to_int, int_to_vocab = create_encoding_dicts(text_list)\n",
    "int_text = encode_text_to_int(text_list, vocab_to_int)\n",
    "pickle_preprocessed_text_data(\"preprocessed_text_data.pkl\", \n",
    "                              [int_text,\n",
    "                               vocab_to_int,\n",
    "                               int_to_vocab,\n",
    "                               TOKEN_LOOKUP\n",
    "                               ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
